https://www.youtube.com/watch?v=QLiKmca4kzI



# Generative AI 现状

Generative AI：输入 一串token 输出选 一个token ，自回归生成，文字接龙。



2025年 新的行为：

1、reasoning 推理过程

2、Deep Research 多步思考

3、ChatGPT Operator 操控物件



Deep Research 机制：

利用  术实现的，效果更好的原因就是 **深度不够，长度来凑**。输出更长 对自回归模型，相当于多走了几层神经网络。



# AI Agent

AI ：人类给一个指令，完成一个动作

AI Agent ：人类给一个目标，AI 达成这个目标



AI Agent 不需要训练新的语言模型，只是使用语言模型来达到 agent 的目的。



举例：ChatGPT Operator

![image-20250923200433939](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923200433939.png)



### 根据经验调整行为

大概分为 read、write、reflection 三个模块

 ![image-20250923202556957](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923202556957.png)

read 模块就是 RAG（下图）。

write 模块也是一个 agent，选择重要的事情写入。

reflection 除了整理除想法外，还可以生成 knowledge graph（GraphRAG）。

![image-20250923201822263](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923201822263.png)

tips：负面的例子记忆基本对效果的提升是无效的。



### Al 如何使用工具

工具：只需使用，不用知道内部原理。使用工具相当于调用函数，又称为 Function call。

举例：搜索引擎、程序、其他模型。



![image-20250923203941426](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923203941426.png)



工具太多就使用一个 tool selection 模块，类似 RAG。

模型也可以自己打造工具，也就是写程序后，保存在工具记忆库中。

![image-20250923204600587](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923204600587.png)



### AI 能不能做計劃

实际上，目前语言模型做规划，还是会经常失误。

![image-20250923212455088](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923212455088.png)



可能的增强方法，根据不同的结果做多路径的规划。

![image-20250923213035440](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923213035440.png)

增强方法存在的问题：

1、路径太长，计算太大

2、覆水难收，action无法回溯

解决方法：

1、让大模型 提前终止错误路径。

2、脑内模拟后，再真正执行。脑内模拟要准确，需要world model，目前用 reasoning 代替。



# 模型內部机制



### 输入输出

embedding：把 token 转化成向量的过程，生成一张 token-向量转化表。

unembedding：把 向量 转化成 toke 的过程，把一个一维向量乘以一个transform变成一个分布。

​							transformer 的一个输出是以为向量，转化成一个3万维的向量，代表字的分布，字的出现概率。



### 一个神经元

一个神经元：输出向量的每一个数值 都是所有输入向量乘以 权重 再相加。



输入 和 神经元 关系分析。

![image-20250926193838097](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250926193838097.png)

图中1：只能观察相关性

图中2：移除方法，可以取这个神经元输出的平均值。置0，0可能有意义。最合适的方法尚待研究。

图中3：脏话等级不好确定，不一定能用这个方法。



一个输出，多数情况下 由很多神经元共同管理。推测是一组特定的神经元管理一个输出。

一个神经元，一般 也影响多个输出。



### 一层神经元



因为 一组特定的神经元的某种向量形式管理一个输出。

怎么找到一个输出对应哪一层的那组神经元的输出向量呢。



比如我们要找到 代表拒绝的一组神经元的输出向量。

1、假设某一层存在一组神经元的输出向量代表拒绝，按图示方法找到。

![image-20250926200652575](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250926200652575.png)

2、把 拒绝这组输出向量 加到 正常的这层神经元的 输出向量representation上，如果正常的输入，也拒绝了，就可以验证。

![image-20250926201413899](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250926201413899.png)

找到很多这种功能向量后，可以加减这些向量，功能也会对应加减。



那一层神经元的输出，有很多的功能向量组成，怎么找到一层神经元的所有功能向量呢

![image-20250926204844427](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250926204844427.png)

1、这层神经元的输出 h 可以由 不同的功能向量 V  + 无用向量 e 构成。注意，功能向量个数是超参数。

2、每次这层神经元的输出都完成一个主要任务，如果训练得好的话，功能向量个数不会多，无用向量e不会大。

3、根据2的两个假设，写出损失函数，使用SAE求解。



### 一群神经元

把模型的某一层输出做 unembedding，得到我们可理解的输出 Logit Lens

![image-20250926221119571](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250926221119571.png)

把residual 后的合成向量 和之前的原始向量都做unembedding，然后比较，就可以看出这一层神经网络做了什么

把 这层神经网络输入中的每一个神经元 的计算 也都可以表示成一个向量，做unembedding，也可以看出这一个神经元做了什么

![image-20250926222132347](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250926222132347.png)



### 神经网络编辑

![image-20250926222426877](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250926222426877.png)

















































































