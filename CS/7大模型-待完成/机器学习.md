https://www.youtube.com/watch?v=QLiKmca4kzI



# Generative AI 现状

Generative AI：输入 一串token 输出选 一个token ，自回归生成，文字接龙。



2025年 新的行为：

1、reasoning 推理过程

2、Deep Research 多步思考

3、ChatGPT Operator 操控物件



Deep Research 机制：

利用 Testing Time Scaling 技术实现的，效果更好的原因就是 **深度不够，长度来凑**。输出更长 对自回归模型，相当于多走了几层神经网络。



# AI Agent

AI ：人类给一个指令，完成一个动作

AI Agent ：人类给一个目标，AI 达成这个目标



AI Agent 不需要训练新的语言模型，只是使用语言模型来达到 agent 的目的。



举例：ChatGPT Operator

![image-20250923200433939](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923200433939.png)



### 根据经验调整行为

大概分为 read、write、reflection 三个模块

 ![image-20250923202556957](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923202556957.png)

read 模块就是 RAG（下图）。

write 模块也是一个 agent，选择重要的事情写入。

reflection 除了整理除想法外，还可以生成 knowledge graph（GraphRAG）。

![image-20250923201822263](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923201822263.png)

tips：负面的例子记忆基本对效果的提升是无效的。



### Al 如何使用工具

工具：只需使用，不用知道内部原理。使用工具相当于调用函数，又称为 Function call。

举例：搜索引擎、程序、其他模型。



![image-20250923203941426](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923203941426.png)



工具太多就使用一个 tool selection 模块，类似 RAG。

模型也可以自己打造工具，也就是写程序后，保存在工具记忆库中。

![image-20250923204600587](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923204600587.png)



### AI 能不能做計劃

实际上，目前语言模型做规划，还是会经常失误。

![image-20250923212455088](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923212455088.png)



可能的增强方法，根据不同的结果做多路径的规划。

![image-20250923213035440](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250923213035440.png)

增强方法存在的问题：

1、路径太长，计算太大

2、覆水难收，action无法回溯

解决方法：

1、让大模型 提前终止错误路径。

2、脑内模拟后，再真正执行。脑内模拟要准确，需要world model，目前用 reasoning 代替。



# 1





















































