prompt 



套壳（API，GPTs）



私有知识库（RAG）：加记忆

Agent：加手脚



微调

训练



----

提示词



向量数据库

LangChain：https://python.langchain.com/docs/get_started/quickstart.html

本地部署



transformer

LLM









# 简单原理

**训练**：transformer，输入是n个token，输出是一个token

**生成**：输入是n个token，输出是 相加概率为1的k个token中 概率较大的一个token。



# 相关技术

数据



模型设计（transformer）

模型训练（微调）

Benchmark（评测）



memory（知识图谱，向量数据库）

搜索技术

RAG



# 应用方式

1、prompt 

2、prompt  + memory

3、Agent



# 私有模型



### 数据设计

数据量

数据配比（垂直VS通用，不同数据源）

数据清理（重复，符号）



### 训练

预训练：训练一个base模型

微调：给模型个性化的能力

Alignment：PP0 或者 DPO，规定模型输出



### Benchmark



# Prompt 工程



指示：做什么

上下文：背景信息

示例：给定部分示例，让模型重新学习到我们的要求。加上思考过程更加准确

输入：

输出：格式，长度，特定回答等



# RAG

Retrieval Augmented Generation



### 向量知识库

一些知识库文档  -->  split 成 chunk  -->  chunk转化成向量Vec   -->  构成 chunk:Vec 格式的知识库



### RAG过程

query   -->  embedding 转化为Vec  -->  （召回，排序）查询向量知识库 获取相关的 chunk  -->  构建Prompt（上下文:chunk，输入:query）  -->  model 输出



### hallucination 问题

原因：

​	1、vec 检索不准确

​	2、LLM 模型理解有幻觉



无法解决，只能缓解：在 Prompt 中加入“仅根据上下文回答”



### split chunks

1、按句子切分

```python
# 按照sentence来切分
import re

text = "在这里，我们有一段超过200字的中文文本作为输入例子。这段文本是关于自然语言处理的简介。自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言。在这一领域中，机器学习技术扮演着核心角色。通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言。这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面。随着深度学习技术的发展，自然语言处理的准确性和效率都得到了显著提升。当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等。自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性和智能化水平也具有重要意义。"
# 正则表达式匹配中文句子结束的标点符号
sentences = re.split(r'(。|？|！|\…\…)', text)

# 重新组合句子和结尾的标点符号
chunks = [sentence + (punctuation if punctuation else '') for sentence, punctuation in zip(sentences[::2], sentences[1::2])]
for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

```python
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize

text = ("The Earth's atmosphere is composed of layers, including the troposphere, "
        "stratosphere, mesosphere, thermosphere, and exosphere. The troposphere is "
        "the lowest layer where all weather takes place and contains 75% of the atmosphere's mass. "
        "Above this, the stratosphere contains the ozone layer, which protects the Earth "
        "from harmful ultraviolet radiation.")

# Split the text into sentences
chunks = sent_tokenize(text)

for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```



2、按固定字符数切分

```python
# 按照固定字符数切分
def split_by_fixed_char_count(text, count):
    return [text[i:i+count] for i in range(0, len(text), count)]

# 假设我们按照每100个字符来切分文本
chunks = split_by_fixed_char_count(text, 100)
for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```



3、按照语义切分



4、递归方法：固定字符数 + 语义

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text = """
在这里，我们有一段超过200字的中文文本作为输入例子。这段文本是关于自然语言处理的简介。自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言。在这一领域中，机器学习技术扮演着核心角色。通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言。这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面。随着深度学习技术的发展，自然语言处理的准确性和效率都得到了显著提升。当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等。自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性和智能化水平也具有重要意义。
"""

splitter = RecursiveCharacterTextSplitter(
    chunk_size = 150,
    chunk_overlap = 0,
    length_function = len,
)

trunks = splitter.split_text(text)
for i, chunk in enumerate(trunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```



### 文本的向量化

One-Hot Encoding，词袋模型，TF-IDF

word2vec ，GloVe

BERT，GPT系列

向量数据库，多模态表示



直接使用模型进行文本的向量化

```python
from openai import OpenAI
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv())  # 读取本地 .env 文件，里面定义了 OPENAI_API_KEY
client = OpenAI()

def get_embedding(text, model="text-embedding-ada-002"):
   text = text.replace("\n", " ")
   return client.embeddings.create(input = [text], model=model).data[0].embedding

emb1 = get_embedding("大模型的应用场景很多")
emb2 = get_embedding("大模型")
emb3 = get_embedding("大模型有很多应用场景")
emb4 = get_embedding("Java开发")
```



向量相似度计算

```
import numpy as np

def cosine_similarity(A, B):
    dot_product = np.dot(A, B)
    norm_A = np.linalg.norm(A)
    norm_B = np.linalg.norm(B)
    return dot_product / (norm_A * norm_B)
    
cosine_similarity(emb1, emb2)
```



# 向量数据库

向量数据库：qdrant 



原理：

倒排索引

knn

近似 knn + Product Quantization (PQ)

近似 knn + HNSW



##### Product Quantization

思路：用聚类后的聚类中心代替原始向量，减少存储，加快计算。

1、数据库中有 n条d维的向量，想找到相似向量，需要计算n次d维向量间的距离。

2、如果可以进行聚类，将n条数据聚类到k个聚类中心，用聚类中心代替计算，只需要计算k次d维向量间的距离。

3、但是随着d增大，k个聚类中心也随之指数增大，所以想到将d切成m份，每份单独聚类，然后将m个聚类中心和查询向量的距离相加，k可以减少。

4、将向量转化为聚类后的结果并存储：聚类结果，m个聚类，每个聚类记载k个聚类中心索引和聚类中心向量。将向量用聚类中心索引表示。

5、再次查询时，只需要计算新向量和聚类后向量的距离。



步骤：

一、生成码本

1、假设有 n 条数据， 将原始高维向量 d 分割为  m 个互不相交的子向量，每个子向量维度为 d/m。

2、对每个子空间 n * d/m  进行聚类（如k-means），生成 k 个聚类中心（码字）。每个子码本记载聚类中心索引和聚类中心向量，共有m个子码本。



二、将原始向量转化为 PQ code，减少存储需求。

3、将每个子向量替换为对应子空间中最近的聚类中心的索引，每个向量可以用m个索引表示[2，34，1，6]）。

4、只需要存储 **码本** 和 **每个向量的 m个索引** 即可，大幅减少存储需求。

![image-20250423180953025](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250423180953025.png)



三、查询码本，加快查询速度。

1、将查询向量分割为子向量，计算子向量和码本所有聚类中心的距离，形成距离查找表。

![image-20250423182129115](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250423182129115.png)

2、对数据库中每个向量，根据距离查找表和 存储的每个向量的 m个索引，计算出查询向量和数据库向量近似总距离，选出距离最短的几个。



##### NSW

基于图的搜索

![image-20250423212939741](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250423212939741.png)

查询图

1、选择任意1个点，计算query点和这个点相连的所有 friend点 的距离，选择距离最短的点走过去

2、重复这个过程，直到某个点是 它所有 friend点中 和 query点 距离最近的为止。



构建图

1、加入1个点，计算所有点和这个点的距离，选择距离最短的n个点和新加入的点相连

2、可以抽象为开始的点连接的远，是高速公路，后面的点连接的近，是小路。先走高速，再走小路，比一直走小路计算效率高。



问题

1、查询图的时候，某点虽然是它 所有 friend点中 和 query点 距离最近的，但是还有别的点更近，达到了局部最优。

​      解决：多运行几遍

2、构建图的时候，越后面的点计算量越大。按照找近似向量的优化方法，如PQ，进行优化

 

##### HNSW

![image-20250423214111825](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250423214111825.png)



1、使用NSW 生成图后，每个点有一定的概率，如40%，向上一层复制1个点，重复得到几层

2、查图时，先从最上层查询，因为概率是40%，所以最上层的点最少，线段最长。找到点后，再向下一层查询，重复到最后一层。



# LLM 推荐系统

![image-20250424221720392](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20250424221720392.png)



# Agent















































































