参考：https://www.modb.pro/db/241774

数据治理：https://www.51cto.com/article/701882.html



# 数仓&数据库

数据库和数据仓库没有使用工具的区别，更多的是思想和规范的区别，不同的工具只是对数据库和数仓有一个更好的支持。



数据库与数据仓库的区别实际讲的是 OLTP（联机事务处理/操作型处理） 与 OLAP（联机分析处理/分析型处理） 的区别。 

传统数据库/OLTP：存储业务数据，面向事务，增删改查。为了实时捕获数据，记录。

数据仓库/OLAP：存储历史数据，面向主题，分析决策。为了事后分析数据，汇总加工。



数仓不是数据库的替代，是在数据库已经存在的情况下，为了进一步挖掘数据资源而产生的。



# 数仓理论

### 范式理论

范式 就是 关系建模中 必须要遵循的规则。



采用范式的目的：降低数据的冗余性，同样数据只存一份。

`减少存储，修改时保持数据一致`



目前大部分关系建模只遵守到第三范式，范式必须由前往后遵守：

`函数依赖：列x可以推迟列y的值，y即函数依赖于x`



第一范式：属性不可切割。

`看每个字段属性是否可切割`



第二范式：非主键字段 不能存在"部分函数依赖" 于主键字段 。就是不能用 主键的一部分信息 确定非主键字段值。

`联合主键的时候，是否存在其中一个主键就可以推出其他字段值的情况`



第三范式：非主键字段 不能存在"传递函数依赖" 于主键字段 。不能某一非主键字段 确定 其他非主键字段值。

`找到所有字段之间的函数依赖，看看是否存在 主键-列1-列2 这样的传递函数依赖`



数据库三范式的最终目的就：列值只能由主键或者联合主键确定。



### 关系建模

关系建模将数据抽象为 实体 和 关系。

每张表都是一个实体，表与表之间有关系。

严格遵守三范式，数据冗余低，查询复杂。



### 维度建模

维度建模将数据抽象为 事实 和 维度。

表关系采用 星型模型 或者雪花模型。关系简单。

不遵守三范式，面向分析，数据冗余。



维度表： 对事实的描述信息（who，where，when，what）。

事实表：一个事实表，反应一个业务流程（下单、支付、评价、退款）。由与维表相连接的外键 和 数值型的度量值组成。

```
事务型事实表：发生即不会改变的事务。如订单记录，支付记录。采用增量更新。
周期型事实表：不关系明细，只关心结果的数据。如每天账号余额。采用全量更新。
累计型事实表：随时间变化的业务，如物流表。采用增量及变化更新。
```



星型模型：一个事实表关联多个维度表。

雪花模型：一个事实表关联多个维度表，维度表部分遵从了三范式，又拆分，然后关联了其他维度表。

星座模型：上面两种模型的发展组成的，即多个事实表，共用了维度表，即组成了星座模型。现实中数仓多是这种情况。



# 数仓维护

- 数据仓库：Hive
- 数仓工程：IEDA-Git
- 调度工具：dolphinscheduler
- 表结构：知乎表结构、EZDML
- 其他工具：sqoop、DBeaver



#数仓人员

- 数仓工程师：离线数仓的最主要维护人员。
- 算法工程师：加工算法所需数据时，要严格遵循下面所述数仓规范，或在数仓工程师的指导下使用。
- 其他相关技术人员：不可对数仓进行永久性改动，只允许进行查询操作。
- 其他非技术人员：提出需求，由数仓工程师加工即可。



请数仓工程师按照数仓规范 维护数仓，每个数仓更改需要在hive，工程，调度，表结构中同步，每个对数仓的永久更改要在数仓工程师内部同步。
其他人员对数仓上述4个部分任一修改，需要通知数仓工程师。

特殊：如果和现有脚本功能部分重合，现有脚本又不能满足需求，可以写一个临时脚本放入tmp文件夹中，后续由数仓工程师统一维护。
如有其他问题，可以询问数仓同事。



# 数仓分层

![image-20211208095202006](https://raw.githubusercontent.com/zhanghongyang42/images/main/image-20211208095202006.png)





ODS：存储原始数据，dim 和 dwd 层负责数据清洗

DIM：维表层，一张表是一个维度，可以是用户，商品，也可以是商家，店铺，研究所，品牌、商品品类，时间，地点。维度之间有关联的采用雪花模型。

DWD：明细层，一张表是一个事件，每个事件表的字段为 维度外键和度量值，或者维度退化的静态属性。跨事件查询，多事件表，如点击-加购-下单事件。

DWI：轻度汇总层，按维度进行汇总，一个维度或者组合维度一张表，字段为度量值按维度的统计值。作用以时间换空间。

DWS：汇总数据层，对dwi的度量值进行进一步统计。

APP	应用数据层，根据业务需求形成的面向应用场景的数据层。指定维度-事件，事件下的度量值，维度的静态属性。

ext：数据加密层，处理进入数仓前需要加密的数据

test：测试数据层，各层需要的临时测试数据表



dim 数据来自 ods 。dim的维表都是单维度维表，可以有主外键关联

dwd 数据来自 ods。除了单事件表，跨事件表也在这一层。

dwi 数据来自 dwd。事件度量值的统计表，除了单维度度量值的聚合，还有多维度度量值的聚合。

dws 数据来自 dwi。同dwi，是更粗粒度的。

app 数据来自 除ods的各层。不同维度的静态属性交互在app层完成。



跨事件字段 在dwd层生成新的多事件表。

多维度聚合统计字段 在dwi层 多维度表实现。

不同维度（用户，商品）的静态属性交互，在app层完成。



# 数仓规范

https://zhuanlan.zhihu.com/p/401982516



表存储格式使用 parquet，ext、ods、app使用 text 。



压缩算法（除ods，app） 使用snappy 压缩。



分区保存时间（具体写在各层目录下）。



# 命名规范

### 主题域

- user     用户主题域 （包括会员、研究所资产管理员、商家）
- product  商品主题域
- order    订单主题域
- flow     流量主题域 （包括用户埋点日志、系统服务日志）
- market   市场营销主题域
- finance  财务主题域



### 表命名

除固定下划线外，表名称建议采用驼峰命名。

- EXT层：ext\_来源库\_表名\_分区策略
- ODS层：ods\_来源库\_表名\_分区策略
- DIM层：dim\_主题域\_表名\_分区策略
- DWD层：dwd\_主题域\_表名\_分区策略
- DWI层：dwi_主题域\_维度名称
- DWS层：dws_主题域\_维度名称
- APP层：
- test层：表名称不限，尽量规范即可



### 脚本命名

- ext脚本： 工具\_数据源\_目标\_每日首日.sh

- ods脚本： 工具\_数据源\_目标\_每日首日.sh

- dim脚本： 表名称\_每日首日.sh

- dwd脚本： 表名称\_每日首日.sh

- dwi脚本： 表名称\_每日首日.sh

- dws脚本： 表名称\_每日首日.sh

- app脚本：

  

所有脚本因为要在linux系统运行，创建脚本时文档格式要选用UNIX格式。



### 字段类型

仅作为参考，符合要求即可。

- 数量类型  bigint

- 数值类型 double

- 金额类型  decimal(16, 2)

- 字符串类型 string

- 主键外键类型 string

- 时间类型 string

  

# ODS

### 保存时间

ODS层数据永久保存。

ods层表名称与表字段类型尽量保持与数据源一致。



### 加载方式

- 使用 sqoop 从 数据库中 加载原始数据。

- 使用 神策提供的导出方法 从 神策日志数仓中 加载原始数据。

  

### 分区策略

- 首日加载：建表、所有数据加载到当日分区。

- 每日加载：首日一次、每日全量、每日增量、每日增变。
  根据不同的每日加载策略放在对应分区下。

  


| 加载策略 | 首日分区 | 每日分区   | 每日分区   |
| -------- | -------- | ---------- | ---------- |
| 首日一次 | 全量     |            |            |
| 每日全量 | 全量     | 全量       | 全量       |
| 每日增量 | 全量     | 增量       | 增量       |
| 每日增变 | 全量     | 增量及变化 | 增量及变化 |



### 策略命名

- 首日一次  once，适用于时间表，地区表这种长久不会变化的表，只需加载一次。
- 每日全量  full，适用于余额表，单位表等，比较小数据量(50万)或者我们只关心它最终结果的表 ，每日全量加载。
- 每日增量  ince，适用于只会增加，不会删改的表，如点击日志，每日增量加载。
- 每日增变  upsert 适用于比较大，且会增加和删改的表，每日增加及变化加载。



### 注意

`tips：从ODS层向其他层抽取数据的时候，会默认把ODS层的LZO索引文件当成数据文件进行合并。所以需要在命令行设置`

`set hive.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat;`



# DIM

### 开发流程

1. 确定要开发的维度，如商品维度。
2. 根据业务库的表关系，找到商品所有相关联的表。
3. 设计商品维度表，在hive创建商品维度表。
4. 设计维度表分区 ，写脚本 从ODS层加载数据到商品维度表。



### 保存时间

DIM层数据永久保存。



### 分区加载策略

维度表由ods单表生成：once 还是once，full还是full，incr还是incr，upsert 可以用拉链表（查询每日状态的数据）

| 加载策略      | 首日分区     | 每日分区     | 每日分区     |
| ------------- | ------------ | ------------ | ------------ |
| 首日一次 once | 全量         |              |              |
| 每日全量 full | 全量         | 全量         | 全量         |
| 每日增量 incr | 全量         | 增量         | 增量         |
| 拉链表 zipper | 首日历史数据 | 每日历史数据 | 9999最新数据 |

数据量小的话，增量和拉链表也可以不分区。



维度表可能由ods的几张表生成，一般是在星型模型中，一般这几张表中会混合once ，full，incr，upsert  ：

`多表join记得从表的关联字段要唯一，不然会多数据`

​	1.选定一张主表（一般是upsert  ），主表需要进行拉链，所以合起来的大表也是拉链表

​	2.首日都是全量数据，直接按照逻辑join即可

​	3.拉链表每日加载逻辑，9999旧表，当日新表，full join所有字段组成临时表，临时表自己union即可。9999旧表容易得到

​			每日加载中once，full，incr 新表 都可以得到当日的全量数据，直接按照首日逻辑join到主表上即可得到新表，

​			主表从表都是upsert，有以下几种方法处理

```
两张表比较小，通过窗口函数id，date，找出两张表当日最新状态，然后进行关联即可
```

```
当日新表，通过所有表去重id生成的临时表，left join所有表生成，其余同每日加载逻辑
```

```
或者分别拉链，在合并成为新的拉链表
```



### 拉链表

拉链表中包括用户过去状态和现在状态的数据，用start_time和end_time两个字段维护，其中现在状态就是end_time=9999。

当用户表发生新增或修改的时候，便向拉链表中插入新数据start_time=当日日期 end_time=9999，同时更新拉链表已有数据的状态 end_time=当日日期。

hive中用分区维护结束日期。



制作拉链表

```sql
--建表
DROP TABLE IF EXISTS dim_user_info;
CREATE EXTERNAL TABLE dim_user_info(
    `id` STRING COMMENT '用户id',
    `name` STRING COMMENT '用户姓名',
    `phone_num` STRING COMMENT '手机号码',
    `email` STRING COMMENT '邮箱',
    `user_level` STRING COMMENT '用户等级',
    `birthday` STRING COMMENT '生日',
    `gender` STRING COMMENT '性别',
    `create_time` STRING COMMENT '创建时间',
    `operate_time` STRING COMMENT '操作时间',
    `start_date` STRING COMMENT '开始日期',
    `end_date` STRING COMMENT '结束日期'
) COMMENT '用户表'
PARTITIONED BY (`dt` STRING)
STORED AS PARQUET;
```

首日加载

```sql
-- 结束日期的值为9999-99-99代表是最新状态的历史数据。
-- 首日加载数据，加载全部数据，并放到9999分区。。
insert overwrite table dim_user_info partition(dt='9999-99-99')
select
    id,
    md5(name),
    md5(phone_num),
    md5(email),
    user_level,
    birthday,
    gender,
    create_time,
    operate_time,
    '2020-06-14',
    '9999-99-99'
from ods_user_info
where dt='2020-06-14';
```

每日加载

```sql
-- 每日加载数据逻辑
-- ods层的每日用户表 和 dim层用户表的最新状态子表 进行Full join，命名成tmp。
-- 重合部分就是要修改的，ods特有部分就是要增加的，dim特有部分就是不变的。
-- 通过nvl函数直接拿到ods所有值和dim不用变的值，然后重合的dim需要更新结束时间。两者union。

set hive.exec.dynamic.partition=true;--动态分区
set hive.exec.dynamic.partition.mode=nonstrict;

with 
old_tbl as (select * from dim_user_info where dt='9999-99-99'),
new_tbl as (select 
            id new_id,
            md5(name) new_name,
            gender new_gender,
            create_time new_create_time,
            operate_time new_operate_time,
            '2020-06-15' new_start_date,
            '9999-99-99' new_end_date 
            from ods_user_info where dt='2020-06-15'),
tmp as (select * from old_tbl full outer join new_tbl on old.id=new.id)

insert overwrite table dim_user_info partition(dt)
select
    nvl(new_id,id),
    nvl(new_name,name),
    nvl(new_gender,gender),
    nvl(new_create_time,create_time),
    nvl(new_operate_time,operate_time),
    nvl(new_start_date,start_date),
    nvl(new_end_date,end_date),
    nvl(new_end_date,end_date) dt
from tmp
union all
select
    id,
    name,
    gender,
    create_time,
    operate_time,
    start_date,
    cast(date_add('2020-06-15',-1) as string),
    cast(date_add('2020-06-15',-1) as string) dt
from tmp
where new_id is not null and old_id is not null;
```



读取拉链表

```
读取最新数据：过滤条件 结束日期 = 9999-99-99 即可。

读取历史数据：过滤条件 开始日期 <= 某个日期 and  结束日期 >= 某个日期。hive中，结束时间可以用分区字段代替
```

拉链表回滚

```
如4月6号 2022-04-05 的数据拉链出错。
end_time<2022-04-05 的数据保留。
start_time>2022-04-05 的数据删除。
其他数据的 end_time 改为9999即可。
以上操作恢复了拉链表，后续还需要从2022-04-06开始执行补数。
```



### 清洗规范

无意义列，缺失值、字段类型、特殊列的处理



### 维度表整理

dim 层 时间地区 表比较特殊，暂时不参与。

```
dim.dim_common_date_once
dim.dim_common_area_once
dim.dim_common_station_area
```



dim 层的维表包括：

|              |                                |
| ------------ | ------------------------------ |
| 用户维表     | dim_user_member_zipper         |
| 商品维表     | dim_product_product_zipper     |
| 商家维表     | dim_user_supplier_zipper       |
| 品牌维表     | dim_product_brand_zipper       |
| 商品品类维表 | dim_product_category_all     ? |



# DWD

### 保存时间

DIM层数据永久保存。



### 分区加载策略

业务事实表分为事务型事实表，周期型快照事实表，累计型快照事实表三种。



事务型事实表：发生即不会改变的事务。首日加载从ods首日分区中动态分区，每日加载直接从ods分区加载进DWD分区。

□（0614全量）	□（0615增加）	□（0615增加）				-->				□（0613）	□（0614）	□（0615）



周期型事实表：不关系明细，只关心结果的数据。每日汇总结果，全量更新到当日分区即可。会增变的我们还要状态的大表勉强拉链

□（0614全量）	□（0615全量）	□（0616全量）				-->				□（0614全量）	□（0615全量）	□（0616全量）

□（全量）			 □（增量及变化） □（增量及变化）			 -->				□（9999最新）	□（0615不变）	□（0616不变）



累计型事实表：随时间变化的业务，如物流表。采用增量及变化更新。分区分为日期分区和9999分区。需要多个代表状态的时间字段

累计事实9999分区维护的是未完成状态数据，其他分区维护的是已完成状态数据，已完成后，未完成的记录不再保留。

维表9999分区维护的是最新状态，其他分区维护的是部分历史状态。维表一般查9999分区，累计型事实表查其他分区

□（0614全量）	□（0615增变）	□（0615增变）				-->				□（9999最新）	□（0613不变）	□（0614不变）	□（0615不变）



### 日志加载

因为工程中不涉及对 日志文件加载成表的情况，将相关sql补充在这里。

日志文件增量加载进ods层，ods层日志表只有一个字段。

建表

```sql
DROP TABLE IF EXISTS dwd_action_log;
CREATE EXTERNAL TABLE dwd_action_log(
    `area_code` STRING COMMENT '地区编码',
    `brand` STRING COMMENT '手机品牌',
    `channel` STRING COMMENT '渠道',
    `is_new` STRING COMMENT '是否首次启动',
    `model` STRING COMMENT '手机型号',
    `mid_id` STRING COMMENT '设备id',
    `os` STRING COMMENT '操作系统',
    `user_id` STRING COMMENT '会员id',
    `version_code` STRING COMMENT 'app版本号',
    `during_time` BIGINT COMMENT '持续时间毫秒',
    `page_item` STRING COMMENT '目标id ',
    `page_item_type` STRING COMMENT '目标类型',
    `last_page_id` STRING COMMENT '上页类型',
    `page_id` STRING COMMENT '页面id ',
    `source_type` STRING COMMENT '来源类型',
    `action_id` STRING COMMENT '动作id',
    `item` STRING COMMENT '目标id ',
    `item_type` STRING COMMENT '目标类型',
    `ts` BIGINT COMMENT '时间'
) COMMENT '动作日志表'
PARTITIONED BY (`dt` STRING)
STORED AS PARQUET
LOCATION '/warehouse/gmall/dwd/dwd_action_log'
TBLPROPERTIES('parquet.compression'='lzo');
```

加载数据

```sql
insert overwrite table dwd_action_log partition(dt='2020-06-14')
select
    get_json_object(line,'$.common.ar'),
    get_json_object(line,'$.common.ba'),
    get_json_object(line,'$.common.ch'),
    get_json_object(line,'$.common.is_new'),
    get_json_object(line,'$.common.md'),
    get_json_object(line,'$.common.mid'),
    get_json_object(line,'$.common.os'),
    get_json_object(line,'$.common.uid'),
    get_json_object(line,'$.common.vc'),
    get_json_object(line,'$.page.during_time'),
    get_json_object(line,'$.page.item'),
    get_json_object(line,'$.page.item_type'),
    get_json_object(line,'$.page.last_page_id'),
    get_json_object(line,'$.page.page_id'),
    get_json_object(line,'$.page.source_type'),
    get_json_object(action,'$.action_id'),
    get_json_object(action,'$.item'),
    get_json_object(action,'$.item_type'),
    get_json_object(action,'$.ts')
-- 给 lateral view explode_json_array(get_json_object(line,'$.actions')) tmp 炸出来的列起别名 action，和 ods_log 原来的列进行join
from ods_log lateral view explode_json_array(get_json_object(line,'$.actions')) tmp as action
where dt='2020-06-14' and get_json_object(line,'$.actions') is not null;
```



### 清洗规范

无意义列，缺失值、字段类型、特殊列的处理



### 事实表整理

|                |                                                         |
| -------------- | ------------------------------------------------------- |
| 浏览商品事实表 | dwd_flow_member_good_click_incr                         |
| 购买点击事实表 | dwd_flow_buynowClick_incr                               |
| 搜索点击事实表 | dwd_flow_member_search_click_incr                       |
| 搜索筛选事实表 | dwd_flow_SearchResultFilter_incr                        |
| 收藏点击事实表 | dwd_flow_collectProduct_incr/dwd_flow_collectStore_incr |
| 加购点击事实表 | dwd_flow_addCart_incr                                   |
| 订单事实表     | dwd_order_orders_zipper                                 |
| 订单详情事实表 | dwd_order_orders_goods_zipper                           |



# DWI

选择业务过程→声明粒度（天）→确认维度→确认事实。



每一行代表一个事件，每一列代表一个单一维度或者聚合维度。

|               | 用户 | 商品 | 商家 | 品牌 | 用户-商品 | 用户-品牌 | 用户-商家 | **度量值**       |
| ------------- | ---- | ---- | ---- | ---- | --------- | --------- | --------- | ---------------- |
| 浏览商品详情  | √    | √    | √    |      | √         |           | √         | 次数             |
| 购买点击      | √    | √    | √    | √    | √         | √         | √         | 次数、价格、数量 |
| 搜索点击      | √    | √    | √    |      | √         |           | √         | 次数             |
| 搜索筛选      | √    |      |      | √    |           | √         |           | 次数             |
| 商品收藏点击  | √    | √    | √    |      | √         |           | √         | 次数             |
| 加购点击      | √    | √    | √    | √    | √         | √         | √         | 次数、价格、数量 |
| 订单          | √    |      |      |      |           |           |           | 次数、价格       |
| 订单-订单详情 |      | √    | √    | √    | √         | √         | √         | 次数、价格、数量 |



dwi 层是 将dwd 的事件按照 一个维度多个维度进行度量值的聚合。

一个维度多个事件一张表，按维度 按粒度聚合度量值 作为字段。

永久保存，按分区保存每日汇总结果。



```sql
with 
good_click_tbl as (SELECT product_id, COUNT(1) good_click_count from dwd.dwd_flow_member_good_click_incr WHERE dt='20220601'  group by product_id),
buynowClick_tbl as (select product_id,COUNT(1) buynowClick_count  from  dwd.dwd_flow_buynowClick_incr WHERE dt='20220601' group by product_id),
search_click_tbl as (select product_id,COUNT(1) search_click_count  from  dwd.dwd_flow_member_search_click_incr WHERE dt='20220601' group by product_id),
collectProduct_tbl as (select product_id,COUNT(1) collectProduct_count  from  dwd.dwd_flow_collectProduct_incr WHERE dt='20220601' group by product_id),
addCart_tbl as (select product_id,COUNT(1) addCart_count  from  dwd.dwd_flow_addCart_incr WHERE dt='20220601' group by product_id),
order_tbl as (SELECT  product_id,COUNT(1) order_count from dwd.dwd_order_orders_goods_zipper WHERE dt='99999999' and substr(create_time,0,10)='2022-06-01' group by product_id)

insert overwrite table dwi.dwi_product partition(dt='20220601')
SELECT 
coalesce(good_click_tbl.product_id,buynowClick_tbl.product_id,search_click_tbl.product_id,collectProduct_tbl.product_id,addCart_tbl.product_id,order_tbl.product_id),
nvl(good_click_count,0),
nvl(buynowClick_count,0),
nvl(search_click_count,0),
nvl(collectProduct_count,0),
nvl(addCart_count,0),
nvl(order_count,0)
from good_click_tbl
full join buynowClick_tbl
on good_click_tbl.product_id=buynowClick_tbl.product_id
full join search_click_tbl
on nvl(good_click_tbl.product_id,buynowClick_tbl.product_id)=search_click_tbl.product_id 
full join collectProduct_tbl
on coalesce(good_click_tbl.product_id,buynowClick_tbl.product_id,search_click_tbl.product_id)=collectProduct_tbl.product_id 
full join addCart_tbl
on coalesce(good_click_tbl.product_id,buynowClick_tbl.product_id,search_click_tbl.product_id,collectProduct_tbl.product_id )=addCart_tbl.product_id 
full join order_tbl
on coalesce(good_click_tbl.product_id,buynowClick_tbl.product_id,search_click_tbl.product_id,collectProduct_tbl.product_id,addCart_tbl.product_id)=order_tbl.product_id ;
```



# DWS

把dwi层的每一个表，进行更粗粒度的聚合（周，月，季，年）。

与dwi层的表一一对应。

保存7日分区即可。



不用每天计算每年的统计值，而是在上一天的统计结果上进行加减实现得到今天汇总值。

建表语句

```sql
DROP TABLE IF EXISTS dwt_user_topic;
CREATE EXTERNAL TABLE dwt_user_topic
(
    `user_id` STRING  COMMENT '用户id',
    `login_date_1d_count` STRING COMMENT '最近1日登录次数',
    `login_day_count` BIGINT COMMENT '累积登录天数',
    `order_date_last` STRING COMMENT '末次下单时间',
    `order_last_1d_count` BIGINT COMMENT '最近1日下单次数',
    `order_last_7d_count` BIGINT COMMENT '最近7日下单次数',
    `order_final_amount` DECIMAL(16,2) COMMENT '累积最终下单金额'
)COMMENT '会员主题宽表'
PARTITIONED BY (`dt` STRING)
STORED AS PARQUET;
```

首日装载

```sql
with
t1 as ( select id,date_format(create_time,'yyyy-MM-dd') login_date_first from dim_user_info where dt='9999-99-99'),
t2 as ( select
        user_id user_id,
        sum(if(dt='2020-06-14',login_count,0)) login_last_1d_count,
        sum(if(login_count>0,1,0)) login_day_count,
        max(if(order_count>0,dt,null)) order_date_last,
        sum(if(dt='2020-06-14',order_count,0)) order_last_1d_count,
        sum(if(dt>=date_add('2020-06-14',-6),order_count,0)) order_last_7d_count,
        sum(if(dt>=date_add('2020-06-14',-29),order_count,0)) order_last_30d_count,
        sum(appraise_default_count) appraise_default_count
    from dwi_user_action_daycount
    group by user_id)
    
insert overwrite table dwt_user_topic partition(dt='2020-06-14')
select
    id,
    nvl(login_last_1d_count,0),
    order_date_last,
    nvl(appraise_default_count,0)
from t1 
left join t2
on t1.id=t2.user_id;
```

每日加载

```sql
with 
old as ( select
        user_id,
        login_date_first,
        login_date_1d_count,
        login_last_7d_count,
        login_last_30d_count,
        login_last_30d_day_count,
        login_count,
        appraise_default_count
    from dwt_user_topic
    where dt=date_add('2020-06-15',-1)),

1d_ago as (select
           user_id,
           login_count,
           appraise_default_count
    from dwi_user_action_daycount
    where dt='2020-06-15'),

7d_ago as ( select
           user_id,
           login_count,
           appraise_default_count
    from dws_user_action_daycount
    where dt=date_add('2020-06-15',-7))

30d_ago as (select
            user_id,
            login_count,
            appraise_default_count
    from dws_user_action_daycount
    where dt=date_add('2020-06-15',-30))

insert overwrite table dwt_user_topic partition(dt='2020-06-15')
select
    nvl(1d_ago.user_id,old.user_id),
    nvl(old.login_date_first,'2020-06-15'),
    if(1d_ago.user_id is not null,1,0),
    nvl(old.login_last_7d_count,0)+nvl(1d_ago.login_count,0)- nvl(7d_ago.login_count,0),
    nvl(old.login_last_7d_day_count,0)+if(1d_ago.user_id is null,0,1)- if(7d_ago.user_id is null,0,1),
    nvl(old.login_day_count,0)+if(1d_ago.user_id is not null,1,0),
    if(old.order_date_first is null and 1d_ago.order_count>0, '2020-06-15', old.order_date_first),
    nvl(old.coupon_used_count,0)+nvl(1d_ago.coupon_used_count,0),
    nvl(1d_ago.appraise_good_count,0),
    nvl(old.appraise_last_7d_good_count,0)+nvl(1d_ago.appraise_good_count,0)- nvl(7d_ago.appraise_good_count,0),
    nvl(old.appraise_default_count,0)+nvl(1d_ago.appraise_default_count,0)
from old
full outer join 1d_ago
on old.user_id=1d_ago.user_id
left join 7d_ago
on old.user_id=7d_ago.user_id
left join 30d_ago
on old.user_id=30d_ago.user_id;
```



# APP

app层一个需求一张表，是dws层多张表的聚合。

一般保存两个分区或者按业务需求时间保存即可。



# 配置SQL调优

详见hive

cdh配置待整理



# 数据质量管理

### 评价指标

| **评价标准** | **描述**                                     | **监控项**                                              |
| ------------ | -------------------------------------------- | ------------------------------------------------------- |
| **唯一性**   | 指主键保持唯一                               | 字段唯一性检查                                          |
|              | 数据量同比环比变化在一定范围内               | 数据量阈值检查                                          |
| **完整性**   | 主要包括记录缺失和字段值缺失等方面           | 字段枚举值检查 <br />字段记录数检查 <br />字段空值检查  |
| **精确度**   | 数据生成的正确性，数据在整个链路流转的正确性 | 波动阀值检查                                            |
| **合法性**   | 主要包括格式、类型、域值的合法性             | 字段日期格式检查  <br />字段长度检查 <br />字段值域检查 |
| **时效性**   | 主要包括数据处理的时效性                     | 批处理是否按时完成                                      |



### 实现方式

通过写python或者shell脚本，通过hive sql 的方式进行统计。



# 字段血缘管理

https://mp.weixin.qq.com/s/l67ND90q7QgB_5ae0g9c8w




















































